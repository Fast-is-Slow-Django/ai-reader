import { createClient } from '@/utils/supabase/server'

export const runtime = 'edge'

/**
 * ä½¿ç”¨ Gemini 2.5 Flash TTS ç”Ÿæˆé«˜è´¨é‡è¯­éŸ³
 * æ”¯æŒéŸ³é¢‘ç¼“å­˜ï¼Œå‡å°‘APIè°ƒç”¨
 */
export async function POST(req: Request) {
  try {
    const { text, bookId } = await req.json()

    if (!text) {
      return new Response('Missing text', { status: 400 })
    }

    console.log('ğŸ¤ TTSè¯·æ±‚:', text.substring(0, 50), '| bookId:', bookId || '(æœªæä¾›)')

    // éªŒè¯ç”¨æˆ·èº«ä»½
    const supabase = await createClient()
    const { data: { user }, error: authError } = await supabase.auth.getUser()
    
    if (authError || !user) {
      console.error('âŒ ç”¨æˆ·æœªè®¤è¯')
      return new Response(
        JSON.stringify({ 
          text,
          useBrowserTTS: true,
          error: 'Unauthorized'
        }), 
        {
          status: 200,
          headers: { 'Content-Type': 'application/json' },
        }
      )
    }

    // ğŸ” æŸ¥è¯¢éŸ³é¢‘ç¼“å­˜
    if (bookId) {
      console.log('ğŸ” æŸ¥è¯¢éŸ³é¢‘ç¼“å­˜:', { userId: user.id, text, bookId })
      
      const { data: cachedData, error: cacheError } = await supabase
        .from('vocabulary_cache')
        .select('audio_data, audio_mime_type')
        .eq('user_id', user.id)
        .eq('book_id', bookId)
        .eq('selected_text', text)
        .not('audio_data', 'is', null)
        .maybeSingle()

      if (cachedData && cachedData.audio_data) {
        console.log('âœ… æ‰¾åˆ°éŸ³é¢‘ç¼“å­˜ï¼Œç›´æ¥è¿”å›')
        
        // Base64è§£ç éŸ³é¢‘
        const binaryString = atob(cachedData.audio_data)
        const bytes = new Uint8Array(binaryString.length)
        for (let i = 0; i < binaryString.length; i++) {
          bytes[i] = binaryString.charCodeAt(i)
        }
        
        return new Response(bytes, {
          status: 200,
          headers: {
            'Content-Type': cachedData.audio_mime_type || 'audio/wav',
            'X-Audio-Cache': 'HIT',
          },
        })
      } else {
        console.log('â„¹ï¸ æœªæ‰¾åˆ°éŸ³é¢‘ç¼“å­˜ï¼Œå°†è°ƒç”¨ Gemini TTS')
      }
    }

    console.log('ğŸ¤ ä½¿ç”¨Gemini 2.5 Flash Preview TTSç”Ÿæˆè¯­éŸ³:', text.substring(0, 50))

    // æ£€æŸ¥ API Key
    const apiKey = process.env.GOOGLE_GENERATIVE_AI_API_KEY
    if (!apiKey) {
      console.error('âŒ GOOGLE_GENERATIVE_AI_API_KEY æœªé…ç½®')
      
      // é™çº§ï¼šè¿”å›æ–‡æœ¬è®©å‰ç«¯ç”¨æµè§ˆå™¨TTS
      return new Response(
        JSON.stringify({ 
          text,
          useBrowserTTS: true,
          error: 'API Key not configured'
        }), 
        {
          status: 200,
          headers: { 'Content-Type': 'application/json' },
        }
      )
    }

    // è°ƒç”¨ Gemini 2.5 Flash Preview TTS API
    const response = await fetch(
      `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-tts:generateContent?key=${apiKey}`,
      {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          contents: [{
            parts: [{
              text: text
            }]
          }],
          generationConfig: {
            responseModalities: ['AUDIO'],
            speechConfig: {
              voiceConfig: {
                prebuiltVoiceConfig: {
                  voiceName: 'Kore'  // è‹±è¯­å¥³å£°
                }
              }
            }
          }
        })
      }
    )

    if (!response.ok) {
      const errorText = await response.text()
      console.error('âŒ Gemini TTS APIé”™è¯¯:', errorText)
      
      // é™çº§ï¼šè¿”å›æ–‡æœ¬è®©å‰ç«¯ç”¨æµè§ˆå™¨TTS
      return new Response(
        JSON.stringify({ 
          text,
          useBrowserTTS: true,
          error: 'Gemini TTS error, using browser TTS'
        }), 
        {
          status: 200,
          headers: { 'Content-Type': 'application/json' },
        }
      )
    }

    const data = await response.json()
    console.log('ğŸ“Š Geminiå®Œæ•´å“åº”:', JSON.stringify(data, null, 2))
    console.log('ğŸ“Š å“åº”æ•°æ®ç±»å‹:', typeof data)
    console.log('ğŸ“Š æ˜¯å¦æœ‰candidates:', !!data.candidates)
    if (data.candidates) {
      console.log('ğŸ“Š candidatesé•¿åº¦:', data.candidates.length)
      console.log('ğŸ“Š ç¬¬ä¸€ä¸ªcandidate:', JSON.stringify(data.candidates[0], null, 2))
    }
    
    // æŒ‰ç…§å®˜æ–¹SDKç¤ºä¾‹è§£æï¼šresponse.candidates[0].content.parts[0].inline_data.data
    if (data.candidates && 
        data.candidates[0] && 
        data.candidates[0].content && 
        data.candidates[0].content.parts &&
        data.candidates[0].content.parts[0] &&
        data.candidates[0].content.parts[0].inlineData) {
      
      const audioData = data.candidates[0].content.parts[0].inlineData.data
      
      if (audioData) {
        console.log('âœ… è·å–åˆ°Gemini TTSéŸ³é¢‘æ•°æ® (PCMæ ¼å¼)')
        
        // Base64è§£ç éŸ³é¢‘ (Edge runtimeå…¼å®¹)
        const binaryString = atob(audioData)
        const pcmBytes = new Uint8Array(binaryString.length)
        for (let i = 0; i < binaryString.length; i++) {
          pcmBytes[i] = binaryString.charCodeAt(i)
        }
        
        // æ„å»ºWAVæ–‡ä»¶å¤´ (PCM 24000Hz, 16bit, mono)
        const sampleRate = 24000
        const numChannels = 1
        const bitsPerSample = 16
        const byteRate = sampleRate * numChannels * bitsPerSample / 8
        const blockAlign = numChannels * bitsPerSample / 8
        const dataSize = pcmBytes.length
        
        // WAVæ–‡ä»¶å¤´ (44å­—èŠ‚)
        const wavHeader = new Uint8Array(44)
        const view = new DataView(wavHeader.buffer)
        
        // "RIFF" chunk descriptor
        view.setUint32(0, 0x52494646, false) // "RIFF"
        view.setUint32(4, 36 + dataSize, true) // file size - 8
        view.setUint32(8, 0x57415645, false) // "WAVE"
        
        // "fmt " sub-chunk
        view.setUint32(12, 0x666d7420, false) // "fmt "
        view.setUint32(16, 16, true) // sub-chunk size
        view.setUint16(20, 1, true) // audio format (1 = PCM)
        view.setUint16(22, numChannels, true) // number of channels
        view.setUint32(24, sampleRate, true) // sample rate
        view.setUint32(28, byteRate, true) // byte rate
        view.setUint16(32, blockAlign, true) // block align
        view.setUint16(34, bitsPerSample, true) // bits per sample
        
        // "data" sub-chunk
        view.setUint32(36, 0x64617461, false) // "data"
        view.setUint32(40, dataSize, true) // data size
        
        // åˆå¹¶WAVå¤´å’ŒPCMæ•°æ®
        const wavFile = new Uint8Array(44 + dataSize)
        wavFile.set(wavHeader, 0)
        wavFile.set(pcmBytes, 44)
        
        // ğŸ’¾ ä¿å­˜éŸ³é¢‘åˆ°ç¼“å­˜
        if (bookId && user) {
          console.log('ğŸ’¾ ä¿å­˜éŸ³é¢‘åˆ°ç¼“å­˜')
          
          // å°†WAVæ–‡ä»¶è½¬ä¸ºBase64
          let wavBase64 = ''
          const chars = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/'
          const bytes = wavFile
          const len = bytes.length
          
          for (let i = 0; i < len; i += 3) {
            const byte1 = bytes[i]
            const byte2 = i + 1 < len ? bytes[i + 1] : 0
            const byte3 = i + 2 < len ? bytes[i + 2] : 0
            
            const encoded1 = byte1 >> 2
            const encoded2 = ((byte1 & 3) << 4) | (byte2 >> 4)
            const encoded3 = ((byte2 & 15) << 2) | (byte3 >> 6)
            const encoded4 = byte3 & 63
            
            wavBase64 += chars[encoded1] + chars[encoded2]
            wavBase64 += i + 1 < len ? chars[encoded3] : '='
            wavBase64 += i + 2 < len ? chars[encoded4] : '='
          }
          
          // æ›´æ–°æ•°æ®åº“ä¸­å¯¹åº”çš„è®°å½•
          const { error: updateError } = await supabase
            .from('vocabulary_cache')
            .update({
              audio_data: wavBase64,
              audio_mime_type: 'audio/wav',
            })
            .eq('user_id', user.id)
            .eq('book_id', bookId)
            .eq('selected_text', text)
          
          if (updateError) {
            console.error('âŒ ä¿å­˜éŸ³é¢‘ç¼“å­˜å¤±è´¥:', updateError)
          } else {
            console.log('âœ… éŸ³é¢‘å·²ä¿å­˜åˆ°ç¼“å­˜')
          }
        }
        
        // è¿”å›WAVéŸ³é¢‘æµ
        return new Response(wavFile, {
          status: 200,
          headers: {
            'Content-Type': 'audio/wav',
            'X-Audio-Cache': 'MISS',
          },
        })
      }
    }

    console.warn('âš ï¸ æœªæ‰¾åˆ°éŸ³é¢‘æ•°æ®ï¼Œé™çº§ä½¿ç”¨æµè§ˆå™¨TTS')
    
    // é™çº§æ–¹æ¡ˆ
    return new Response(
      JSON.stringify({ 
        text,
        useBrowserTTS: true 
      }), 
      {
        status: 200,
        headers: { 'Content-Type': 'application/json' },
      }
    )

  } catch (error) {
    console.error('âŒ ç”Ÿæˆè¯­éŸ³å¤±è´¥:', error)
    return new Response(
      JSON.stringify({ 
        error: 'Failed to generate audio',
        details: error instanceof Error ? error.message : 'Unknown error'
      }), 
      { 
        status: 500,
        headers: { 'Content-Type': 'application/json' }
      }
    )
  }
}
